{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca82758-38aa-4b37-9afd-12575aeed64e",
   "metadata": {},
   "source": [
    "# Exercise 5c: More ML on graphs\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we assume that you have already populated your Wikidata (AKA \"Method 2\") database, which was shown in Exercises 3 and 4. We also will assume that you have run the Cypher queries found in cypher_queries/method2_queries.cql to do things like update the node labels to the P31 values, segment out both model and holdback data, and create some basic embeddings.\n",
    "\n",
    "No worries if you need to spin up a new Sandbox instance.  There is an optional cell below for repopulating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0422ef1-8f2a-405a-a1c4-efb5227fd305",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import re\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b5d38e-39c2-443e-b9ec-b68774dc6a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jConnection:\n",
    "    \n",
    "    def __init__(self, uri, user, pwd):\n",
    "        self.__uri = uri\n",
    "        self.__user = user\n",
    "        self.__pwd = pwd\n",
    "        self.__driver = None\n",
    "        try:\n",
    "            self.__driver = GraphDatabase.driver(self.__uri, auth=(self.__user, self.__pwd))\n",
    "        except Exception as e:\n",
    "            print(\"Failed to create the driver:\", e)\n",
    "        \n",
    "    def close(self):\n",
    "        if self.__driver is not None:\n",
    "            self.__driver.close()\n",
    "        \n",
    "    def query(self, query, parameters=None, db=None):\n",
    "        assert self.__driver is not None, \"Driver not initialized!\"\n",
    "        session = None\n",
    "        response = None\n",
    "        try: \n",
    "            session = self.__driver.session(database=db) if db is not None else self.__driver.session() \n",
    "            response = list(session.run(query, parameters))\n",
    "        except Exception as e:\n",
    "            print(\"Query failed:\", e)\n",
    "        finally: \n",
    "            if session is not None:\n",
    "                session.close()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c130b3-2160-46c9-b575-7f85957689cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = ''\n",
    "user = 'neo4j'\n",
    "pwd = ''\n",
    "\n",
    "conn = Neo4jConnection(uri=uri, user=user, pwd=pwd)\n",
    "conn.query(\"MATCH (n) RETURN COUNT(n)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06256a8e-0fa0-43e8-bb11-cda61e358782",
   "metadata": {},
   "source": [
    "## If you need to repopulate the Sandbox instance, run the following two cells..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a720d141-0dbc-412c-9260-1fcff5bc499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_url = 'https://resources.oreilly.com/binderhub/introduction-to-knowledge-graphs/raw/master/data/wiki.json'\n",
    "\n",
    "query = \"CALL apoc.import.json('\" + wiki_url + \"')\"\n",
    "conn.query(query)\n",
    "\n",
    "conn.query(\"MATCH (n) RETURN COUNT(n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abdc78e-e6b9-4b43-a84e-56b98e83153a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"MATCH (n:Node) \n",
    "           WITH n.name AS name, COLLECT(n) AS nodes \n",
    "           WHERE SIZE(nodes)>1 \n",
    "           FOREACH (el in nodes | DETACH DELETE el)\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"MATCH (n:Node) \n",
    "            SET n.type_ls = apoc.convert.toStringList(n.type)\n",
    "\"\"\"\n",
    "\n",
    "query3 = \"\"\"MATCH (n:Node) \n",
    "            CALL apoc.create.addLabels(n, n.type_ls) \n",
    "            YIELD node \n",
    "            RETURN COUNT(node)\n",
    "\"\"\"\n",
    "\n",
    "conn.query(query1)\n",
    "conn.query(query2)\n",
    "conn.query(query3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ca1e0-afa5-4898-adc2-526d55a93634",
   "metadata": {},
   "source": [
    "## Binary classification example: can we identify whether a node is a place or not a place?\n",
    "\n",
    "We are going to try and determine whether a node is a place or not based on our graph.  Let's create a property for our nodes, `is_place` (1 = a place, 0 = otherwise)and see how this works.  I have created an arbitrary list of node labels.  While I tried to be complete, I am sure there are errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc57170-5878-4de2-b7a8-c2e5557d3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"MATCH (n)\n",
    "            WHERE ANY (x in n.type WHERE x IN \n",
    "                        ['county of Illinois', \n",
    "                        'state of the United States',\n",
    "                        'oblast of Russian',\n",
    "                        'province of Afghanistan',\n",
    "                        'province of Iran',\n",
    "                        'oblast of Ukraine',\n",
    "                        'district of Libya',\n",
    "                        'governorate of Iraq',\n",
    "                        'province of Cuba',\n",
    "                        'governorate of Syria',\n",
    "                        'sovereign state',\n",
    "                        'autonomous okrug of Russia',\n",
    "                        'city',\n",
    "                        'krai of Russia',\n",
    "                        'city of the United States',\n",
    "                        'territory of the United States',\n",
    "                        'capital',\n",
    "                        'geographic region',\n",
    "                        'continent',\n",
    "                        'county of Hawaii',\n",
    "                        'village',\n",
    "                        'historical country',\n",
    "                        'autonomous republic',\n",
    "                        'organized incorporated territory',\n",
    "                        'unincorporated territory',\n",
    "                        'census-designated place',\n",
    "                        'human settlement',\n",
    "                        'borough of New York City',\n",
    "                        'Commonwealth realm',\n",
    "                        'city of Pennyslvania',\n",
    "                        'neighborhood of Washington, D.C.',\n",
    "                        'country']\n",
    "                      )\n",
    "            SET n.is_place=1\n",
    "\"\"\"\n",
    "\n",
    "query2 = \"\"\"MATCH (n) WHERE n.is_place IS NULL SET n.is_place=0\"\"\"\n",
    "\n",
    "conn.query(query1)\n",
    "conn.query(query2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911f078-c7f9-462d-a7f9-a7f8efbdda81",
   "metadata": {},
   "source": [
    "## Generate in-memory graph\n",
    "\n",
    "We now are going to creating our in-memory graph.  We do this for all nodes and all relationships which, recall, is not a great idea in general.  However, since our graph is so small, we are going to go with it for the sake of demonstration.  Also recall that most of GDS is looking for an undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8ff40-cbff-4e9c-9ccc-d8ea06bdfa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"CALL gds.graph.create(\n",
    "               'all_nodes',\n",
    "               'Node',\n",
    "               {\n",
    "                   RELS: {\n",
    "                           type: '*',\n",
    "                           orientation: 'UNDIRECTED'\n",
    "                   }\n",
    "               }\n",
    "           )\n",
    "\"\"\"\n",
    "\n",
    "conn.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e028d0a-37c4-4a83-ba99-b4bf908d6190",
   "metadata": {},
   "source": [
    "## Create some embeddings\n",
    "\n",
    "We are going to create two different kinds of 10-dimensional graph embeddings using:\n",
    "\n",
    "1. [node2vec](https://neo4j.com/docs/graph-data-science/current/algorithms/node2vec/)\n",
    "2. [Fast Random Projection](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/) (AKA \"FastRP\")\n",
    "\n",
    "There are many hyperparameters that we are not tuning in this section.  If you would like to know more about them, you can read [this blog post](https://dev.neo4j.com/fastrp_background) on the math behind FastRP and [this blog post](https://dev.neo4j.com/bratanic_node2vec) on that for node2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59683da6-648b-4831-af8c-3d286c1eb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"CALL gds.beta.node2vec.write(\n",
    "               'all_nodes', \n",
    "               { \n",
    "                   embeddingDimension: 10, \n",
    "                   writeProperty: 'n2v_all_nodes'\n",
    "               } \n",
    "           )\n",
    "\"\"\"\n",
    "\n",
    "conn.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7205be8-c19d-4ee7-be15-10c302fca12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"CALL gds.fastRP.write(\n",
    "               'all_nodes',\n",
    "               {\n",
    "                   embeddingDimension: 10, \n",
    "                   writeProperty: 'frp_all_nodes'\n",
    "               }\n",
    "           )\n",
    "\"\"\"\n",
    "\n",
    "conn.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1a616-0b4d-4669-a97a-a68e838b1e32",
   "metadata": {},
   "source": [
    "## t-SNE of our embeddings\n",
    "\n",
    "Let's now use the [t-distributed Stochastic Neighbor Embedding (t-SNE)](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html?highlight=tsne#sklearn.manifold.TSNE) approach of dimensionality reduction to try and visualize the quality of our embeddings.  Recall that we have a node property called `is_place`, which is 1 for all nodes we called a place and 0 otherwise.  So we are going to use this binary classification to see if we can get our classes to form separable clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bb8016-1135-44e8-87b4-5000a7369030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tsne_plot(emb_name='n.n2v_all_nodes', n_components=2, debug=False):\n",
    "    \n",
    "    query_string = '''\n",
    "        MATCH (n:Node)\n",
    "        RETURN n.name, n.type, n.is_place AS category, {} AS vec\n",
    "    '''.format(emb_name)\n",
    "    model_df = pd.DataFrame([dict(_) for _ in conn.query(query_string)])\n",
    "    \n",
    "    if debug:\n",
    "        uniqueValues = model_df['category'].nunique()\n",
    "        print(uniqueValues)\n",
    "    \n",
    "    X_emb = TSNE(n_components=n_components).fit_transform(list(model_df['vec']))\n",
    "    \n",
    "    tsne_df = pd.DataFrame(data = {\n",
    "        'x': [value[0] for value in X_emb],\n",
    "        'y': [value[1] for value in X_emb],\n",
    "        'label': model_df['category']\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(16,10))\n",
    "    s = 30\n",
    "    ax = sns.scatterplot(\n",
    "        x='x', y='y',\n",
    "        palette=sns.color_palette('hls',2),\n",
    "        data=tsne_df,\n",
    "        hue='label',\n",
    "        legend=True, \n",
    "        s=500,\n",
    "        alpha=0.75\n",
    "    )\n",
    "    ax.legend(prop={'size': 20})\n",
    "    plt.xlabel('X Component', fontsize=16)\n",
    "    plt.ylabel('Y Component', fontsize=16)\n",
    "    plt.show\n",
    "\n",
    "    return tsne_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94b66ed-1fe1-42ab-b688-2adc95b91886",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = create_tsne_plot(emb_name='n.n2v_all_nodes', n_components=2, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0f7ad-44da-45a9-bd75-c0d08a2349e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df = create_tsne_plot(emb_name='n.frp_all_nodes', n_components=2, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9f062-c5b7-4cf8-a2a9-06b799819d98",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "OK, that is not so hot.  There are a few small clusters that have very few false positives, but all in all this is nothing to write home about.\n",
    "\n",
    "## _EXERCISE:_ Try some different hyperparameters for the two embedding approaches to see if you can do better.\n",
    "\n",
    "It will help to consult the docs for each, linked above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad2549-7656-42c3-b64e-3ef52cd719ed",
   "metadata": {},
   "source": [
    "## Binary classification model with support vector machines\n",
    "\n",
    "As in the previous ML exercise, we will format our graph data into a format suitable for `scikit-learn` and will run it through our SVC classifier using 5-fold validation.  Unlike previous examples, we will use the built in `class_weight` parameter to attempt to handle the class imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf7464-801d-4d95-923e-4574aa4688b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(df2, emb):\n",
    "\n",
    "    n2v_an_ls = df2[emb].to_list()\n",
    "    n2v_arr = np.array([np.array(x) for x in n2v_an_ls], dtype=object)\n",
    "\n",
    "    print(n2v_arr.shape)\n",
    "    \n",
    "    return n2v_arr\n",
    "\n",
    "\n",
    "def modeler(df, emb_name, y_column_name, k_folds=5, model='linear', show_matrix=True):\n",
    "    \n",
    "    y = df[y_column_name].fillna(0.0).to_numpy()\n",
    "    vec_array = create_X(df, emb_name)\n",
    "    acc_scores = []\n",
    "    \n",
    "    pos = np.count_nonzero(y == 1.0)\n",
    "    neg = y.shape[0] - pos\n",
    "    print('Number of positive: ', pos, ' Number of negative: ', neg)\n",
    "    \n",
    "    for i in range(0, k_folds):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(vec_array, y, test_size=0.25)\n",
    "        clf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(pred, y_test)\n",
    "        acc_scores.append(acc)        \n",
    "        \n",
    "    print('Accuracy scores: ', acc_scores)\n",
    "    print('Mean accuracy: ', np.mean(acc_scores))\n",
    "    \n",
    "    if show_matrix:\n",
    "        matrix = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n",
    "        plt.show(matrix)\n",
    "        plt.show()\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e312bb7-81f9-42ca-99b3-b1da7ddeded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = '''\n",
    "    MATCH (n:Node)\n",
    "    RETURN n.name, n.type, n.is_place AS category, n.n2v_all_nodes AS n2v_vec, n.frp_all_nodes AS frp_vec\n",
    "'''\n",
    "model_df = pd.DataFrame([dict(_) for _ in conn.query(query_string)])\n",
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab595237-5cea-4988-b526-460a7e8a60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_clf = modeler(model_df, emb_name='n2v_vec', y_column_name='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c8a924-5bb7-4119-93d4-0f11b7c70f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frp_clf = modeler(model_df, emb_name='frp_vec', y_column_name='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67acf7d-6568-4b4b-b100-2c5b1030b599",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "Those results aren't _horrible,_ but we definitely see the impact of the class imbalance.  This is just one of those problems with ML with several ways we could attempt to correct it, most of which involving getting more data or manually attempting to balance the classes further.  I live that as an exercise to try after the workshop.\n",
    "\n",
    "## _Exercise:_ play with the embeddings above to try and get a better result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956c6bba-b92c-4fea-bf5e-28442da42703",
   "metadata": {},
   "source": [
    "## Let's see what happens if we give the classifier some nodes that we happen to know the answer for and see how it does\n",
    "\n",
    "Good node names to try are \"Illinois,\" \"Bill Clinton,\" and \"city of the United States\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ceea27-b108-4e5f-a366-2c11435f289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unknown(node_name, emb_name, clf, debug=False):\n",
    "    \n",
    "    query_string = \"MATCH (n:Node {name: '\" + node_name + \"'}) RETURN n.name AS name, n.\" + emb_name + \" AS vec\"\n",
    "    \n",
    "    if debug == True:\n",
    "        print(query_string)\n",
    "        print(type(query_string))\n",
    "        print(emb_name)\n",
    "\n",
    "    unknown_df = pd.DataFrame([dict(_) for _ in conn.query(query_string)])\n",
    "    \n",
    "    vec_array = create_X(unknown_df, emb='vec')\n",
    "    pred = clf.predict(vec_array)\n",
    "    print('Predicted Class: ', pred[0])\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede7c40c-8b9b-4710-841a-fb679264ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_unknown('Illinois', 'n2v_all_nodes', clf=n2v_clf, debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d880da-583b-4bed-904d-981a6ec45ff6",
   "metadata": {},
   "source": [
    "## Trying a new classifier: K Neighbors\n",
    "\n",
    "For the sake of comparison, we can try other classifiers as well.  I have chosen to use the [K Neighbors Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) in this example, but you could pick any classifier really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5021d5a2-2c1f-4383-bbc0-b8d4059abfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knc_modeler(df, emb_name, y_column_name, k_folds=5, model='linear', show_matrix=True):\n",
    "    \n",
    "    y = df[y_column_name].fillna(0.0).to_numpy()\n",
    "    vec_array = create_X(df, emb_name)\n",
    "    acc_scores = []\n",
    "    \n",
    "    pos = np.count_nonzero(y == 1.0)\n",
    "    neg = y.shape[0] - pos\n",
    "    print('Number of positive: ', pos, ' Number of negative: ', neg)\n",
    "    \n",
    "    for i in range(0, k_folds):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(vec_array, y, test_size=0.25)\n",
    "        #clf = svm.SVC(kernel='linear', class_weight='balanced')\n",
    "        #clf.fit(X_train, y_train)\n",
    "        clf = KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "        clf.fit(X_train, y_train)\n",
    "        pred = clf.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(pred, y_test)\n",
    "        acc_scores.append(acc)        \n",
    "        \n",
    "    print('Accuracy scores: ', acc_scores)\n",
    "    print('Mean accuracy: ', np.mean(acc_scores))\n",
    "    \n",
    "    if show_matrix:\n",
    "        matrix = plot_confusion_matrix(clf, X_test, y_test, cmap=plt.cm.Blues, normalize='true')\n",
    "        plt.show(matrix)\n",
    "        plt.show()\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d401d1a-87a4-4b04-8458-8406e016cd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_knc = knc_modeler(model_df, emb_name='n2v_vec', y_column_name='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17d6feb-78d2-4feb-9c12-ed538612f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frp_knc = knc_modeler(model_df, emb_name='frp_vec', y_column_name='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7a620-6ebe-4ed3-9c35-81fbd90339c9",
   "metadata": {},
   "source": [
    "## Observation\n",
    "\n",
    "That is slightly better, if we ignore the class imbalance.  And again, remember that we really haven't spent any time optimizing the embeddings or the model (beyond k-fold validation).  But as per the caveats before, these demonstrations are for educational purposes and not intended to be optimized, especially for such small graphs.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Add more data to the graph (always a good idea when you can and time permits!)\n",
    "2. Optimize the above embeddings (obvious)\n",
    "3. Try the [GraphSAGE](https://neo4j.com/docs/graph-data-science/current/algorithms/graph-sage/) or [Fast RP Extended](https://neo4j.com/docs/graph-data-science/current/algorithms/fastrp/#algorithms-embeddings-fastrp-extended) embedding algorithms.  These two have the advantage of taking into accoun the node properties themselves in addition to the random walks we have used above\n",
    "\n",
    "## Built-in ML Algorithms with GDS\n",
    "\n",
    "The Graph Data Science library does much more than embeddings! In particular, I recommend you check out the [node classification](https://neo4j.com/docs/graph-data-science/current/algorithms/ml-models/node-classification/) and [link prediction](https://neo4j.com/docs/graph-data-science/current/algorithms/ml-models/linkprediction/) modeling capabilities. This small graph might not be able to take much advantage of them, but as the graph gets bigger you might find them to be really helpful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb4352-4602-4c10-a604-b2897f770b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
